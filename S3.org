* S3
S3 provides developers and IT teams with secure, durable, highly-scalable object storage.
Amazon S3 is easyto use, with a simple web services interfaces to store and retrieve any amount
of data from anywhere on the web.

** S3 - The Basics
   - S3 is Object based i.e. allows you to upload files.
   - Files can be from 0 Bytes to 5TB.
   - There is unlimited storage.
   - Files are stored in buckets(bucket is just a folder).
   - S3 is universal namespace, that is, name must be unique globally.
   - When you create a bucket it creates DNS address. Format: "https://s3-eu-west-1.amazonaws.com/acloudguru".
   - When you upload a file to S3 yo will recieve a HTTP 200 code if the upload was succesful.
   - Built for 99.99% availability for the S3 platform.
   - Amazon guarantee 99.9% availability.
   - Amazon guarantees 99.999999999% durability for S3 information(11 x 9's).
   - Tiered Storage available -> [[S3:Tier/Classes]].
   - Life Cicle management.
   - Versioning.
   - Encryption.
   - Secure your data using Access Control Lists and Bucket Policies.

** Storage Tier/Classes
   <<S3:Tier/classes>>
   - S3 - 99.99% availability, 99.999999999% durability, stored redundantly across multiple
     devices in multiple facilities and is designed to sustain the loss of 2 facilities concurrently.
   - S3 - IA(Infrequently Accessed) For data that is accessed less frequently, but requires rapid access
     when needed. Lower fee than S3, but you are charged a retrieval fee.
   - Reduced Redundancy Storage(RRS) - Designed to provide 99.99% durability and 99.99% availability
     of objects over a given year.
   - Glacier - Very cheap, but used for archival only. It takes 3-5 to restore from Glacier. -> [[s3:Glacier]]
   - Table:

     |                                     | Standard      | Standard-IA   | Reduced Redundancy Storage |
     | Durability                          | 99.999999999% | 99.999999999% | 99.99%                     |
     | Availability                        | 99.99%        | 99.9%         | 99.99%                     |
     | Concurrent facility fault tolerance | 2             | 2             | 1                          |
     | SSL support                         | Yes           | Yes           | Yes                        |
     | First byte latency                  | Miliseconds   | Miliseconds   | Miliseconds                |
     | Lifecycle Management Policies       | Yes           | Yes           | Yes                        |


** Glacier
   <<S3:Glacier>>
Its and extremely low-cost storage service for data archival. Amazon Glacier stores data for as little
as $0.01 per gigabyte per month, and is optimized for data that is infrequently accessed and for which
retrieval times of 3 to 5 hours are suitable.

** S3 vs Glacier

|                           | Standard      | Standard-IA      | Amazon Glacier            |
| Designed for Durability   | 99.999999999% | 99.999999999%    | 99.999999999%             |
| Designed for Availability | 99.99%        | 99.9%            | N/A                       |
| Availability SLA          | 99.9%         | 99%              | N/A                       |
| Minimum Object Size       | N/A           | 128KB*           | N/A                       |
| Minimum Storage Duration  | N/A           | 30 Days          | 90 days                   |
| Retrieval Fee             | N/A           | per GB retrieved | per GB retrieved**        |
| First Byte Latency        | Milliseconds  | Milliseconds     | Select minutes or hours** |
| Storage Class             | Object level  | Object level     | Object level              |
| Lifecycle Transitions     | Yes           | Yes              | Yes                       |


** S3-Charges
   - Charged for:
     * Storage -> How much data are you storing.
     * Requests -> For the number of requests.
     * Storage management Pricing -> You can a whole bunch of tags to it, and this allows
       you to control costs so you can know to whom the data is asociated, and so they do charge
       on a per tag basis.
     * Data Transfer Pricing -> Data comming into S3 is free but moving data around S3, maybe doing
       replication from one region to another you will be charged for that.
     * Transfer Acceleration -> [[S3:Transfer-Acceleration]]


** Transfer Acceleration
<<S3:Transfer-Acceleration>>

Amazon S3 Transfer Accelration enables fast, easy, and secure transfers of files over long distances between
your end users and S3 bucket.

Transfer Acceleration tkes adventage of Amazon CloudFront's globally distributed edge locaions. As the data
arrives at an edge location, data is routed to Amazon S3 over an optimized network path.


** Data Consistency Model For S3
   - Read after Write consitency for PUTS of new objects.
   - When you PUT a new object you get inmediately consistency- so you going to be able
     to read that object.
   - Eventual Consistency for overwrite PUTS and DELETES(can take some time to propagate).
   - Updates to S3 are atomic(you're either going to get the new data or you're going to
     get the old data, you wont get partial or corrupted data).

** S3 is a simple key, value store
   - S3 is Object based. Objects consist of the following:
     1. Key -> The name of the object.
     2. Value -> The data and is made up of sequence of bytes.
     3. Version ID -> Important for versioning.
     4. Metadata -> Data about the data you are storing.
     5. Subresources ->
        * Access Control Lists -> This allows you do fine grained permissions so you can
          do an access control it's on individual objects.
        * Torrent -> S3 does support bit torrent protocol.

** Versioning
   - Once turned on it can't be removed, only disabled.
   - In reality is saving the same amount of files than versions, so the size
     of the bucket will be the sum of the verions of all files.
   - You can delete versions.
   - Deleted versions can't be restored.
   - You can restore a deleted object
     -> Select Deleted objects
     -> Select the object
     -> In the more select object, select the unde delete option.
   - Versioning's can add Multifactor Authentication(MFA) to allow delete an object.

** Cross Region Replication
   - In the properties bucket select Cross-region replication.
   - To use a Cross-region replication versioning must be enabled on the souce and target bucket
   - Objects that are already stored on the bucket before the Cross-region replication
     has done are not going to be replicated, will be replicated only new objects and updates.
   - When replicate an update, also replicates all versions.
   - Permissions are also replicated.
   - When You delete an object the delte action will replicate, but the undo delete won't replicate,
     so you willl have to undodelete manually on the replica buccket.
   - The delete version won't replicate.

** Lifecycle Management & Glacier
   - Versioning is optional with lifecycle management but can be used with it.
   - Can be applied to current and previous versions.
   - Actions you can do:
     * Transition to the Standard-Infrequent Access Storage Class.
     * Archive to the Glacier Storage Class.
     * Permanently Delete objects(Will delete from S3 and Glacier).

** Securying your buckets
   - By default, all newly created buckets are private.
   - You can setup access control to your buckets using:
     * Bucket Polices: Permissions are applied to the entire bukcet.
     * Access Control Lists: You can control individual objects
   - S3 buckets can be configured to create access logs which log all requests
     made to the S3 bucket. This can be done to another bucket.

** Encryption
   - In transit: When you're sending information to and from your bucket by SSL/TLS
   - At Rest: The are two ways to do this.
     * Server Side Encryption: There are 3 methods under this way.
       + S3 Managed Keys-SSE-S3: Each object is encypted with a unique key,
         employing strong multifactor encryption, and then as additional safeguard
         Amazon actually encrypt the key itself with master key(256) and they
         regularly rotate that master key.
       + AWS Key Management Service, Managed Keys-SSE-KMS: It's key management
         service, separate permissions for the use of an envelope key, envelope
         key is simply a key tha protects your data encryption key, also tells
         you when your keys where used and who was actually using them.
       + Server Side Encryption With Customer Provided Keys-SSE-C:
         This is when you manage your keys and amazon manage the encryption as
         it writes to disk and decryption when you access to the objects.
     * Client Side Encryption: When you encrypt the data on your client and then
       you upload it to S3.

** Storage Gateway
   - It's a service that connects an on-premises software appliance with
     cloud-based storage to provide seamless and secure integration between an
     organization's on premise IT environment and AWS's storage infraestructure.
     The service enables you to securely store data to AWS cloudfor scalable and
     cost-effective storage.
   - AWS Storage Gateway's software appliance is available for download as a virtual
     machine(VM) image that you install on a host in your datacenter.
     Storage Gateway supports either VMware ESXi or Microsoft Hyper-V. Once you've
     installed your gateway and associated it with your AWS account through the
     activation process, you can use the AWS Management console to create the storage
     gateway option that is right gor you.

** Types of Storage Gateways
   - File Gateway(NFS): This is where you store flat files in S3, so it essentially
     allows you to store word files, pages, videos, etc. and it's stored directly
     on S3.
   - Volumes Gateways(iSCSI): This is using block based storage that you would run
     operating systems on, so it might be  a virtual hard disk that you've got
     a VM running on, it might be a virtual hard disk with SQL Server or MySQL.
     There are two types of this volumes:
     + Stored Volumes: This is where you store an entire copy of your dataset
       on-site or on-premise.If you need low-latency access to your entire data set,
       you can configure your on-premises gateway to store all your data locally
       and then asynchronously back up point-in-time snapshots of this data to
       Amazon S3.
     + Cached Volumes: You store your data in Amazon Simple Storage Service (Amazon S3)
       and retain a copy of frequently accessed data subsets locally.Cached volumes
       offer a substantial cost savings on primary storage and minimize the need to
       scale your storage on-premises.
   - Tape Gateway(VTL): It allows you to create virtual tapes and then send them
     to S3 and then use lifecycle polices to send those tapes of to glacier.

** File Gateway
   - Files are stored as objects in your S3 buckets, accessed through a Network File
     System(NFS) mount point. Ownership, permisions, and timestamps ar durably
     stored in S3 in the user-metadata of the object associated with the file.
     Once objects are transferred to S3, they can be managed as native S3 objects,
     and bucket polices such as versioning, lifecycle management, and cross-region
     replication apply directly to objects stored in your bucket.

** Volume Gateway
   - The volume interface presents your applications with disc volumes using the
     iSCSI block Protocol.
   - Data written to these volumes can be asynchronously backed up as point-in-time
     snapshots of your volumes, and stored in the clouds Amazon EBS snapshots.
   - Snapshots are incremental backups that capture only changed blocks. All snapshot
     storage is also compressed to minimize your storage charges.
   - There are two tes of volume gateways:
     * Stored Volumes: Let you store your primary data locally, while asynchronously
       backing up that data to AWS. Stored Volumes provide your on-premises
       applications with low-latency access to their entire datasets, while providing
       durable, off-site backups. You can create storage volumes and mount then as
       iSCSI devices from your on-premises storage hardware. This data is
       asynchronously backed to Amazon Simple Storage Service(Amazon S3) in the
       form of Amazon Elastic Block Storage(Amazon EBS) snapshots. 1GB-16TB in
       size for Stored Volumes.
     * Cashed Volumes: Let you use Amazon Simple Storage Service(AmazonS3) as
       your primary data storage while retaining frequently accessed data. You
       can create storage volumes up to 32 TB in size and attach to them  as iSCSI
       devices from your on-premises application servers. Your gateway stores data
       that you write to these volumes in Amazon S3 and retains recently read data
       in your on-premises storage gateway's cache and upload buffer storage.
       1GB-32TB in size for cached volumes.
     * Tape Gateway: Offers durable, cost-effective solution to archive your data
       in AWS Cloud. the VTL interface provides lets your leverage your existing
       tape-based backup application infrastructure to store data on virtual tape
       cartridges that you create on your tape gateway. Each tape gateway is
       preconfigured with a media changer and tape drives, which are available
       to your existing client backup applications as iSCSI devices. You add tape
       cartridges as you need to archive your data. Supported by NetBackup,
       Backup Exec, Veeam, etc.

   - Notes:
     * File Gateway: For flat files, stored directly on S3.
     * Volume Gateway
       1. Volume Gateway: Entire Dataset is stored on site and is asynchronously
          backed to S3.
       2. Cached Volumes: Entire Dataset is stored on S3 and the most frequently
          accessed data is cached on site.
     * Gateway Virtual Tape Library(VTL):
       - Used for backup and uses popular backup applications like NetBackup,
         Backup Exec, Veeam etc.


** Snowball
   - Is a petabyte-scale data transport solutionthat uses secure appliances to
     transfer large amounts of data into and out of AWS. Using Snowball addresses
     common challenges with large-scale data transfers including high network
     costs, long transfer times, and security concerns. Transferring data with
     Snowball is simple fast, secure, and can be as little as one-fifth the cost
     of high-speed Internet.
     80TB snowbal in all regions. Snowball uses multiple layers of security
     designed to protect your data including tamper-resistant enclosures, 256-bit
     encryption, and an industry-standard Trusted Platform Module(TPM) designed
     to ensure both security and ful chain-of-custody of your data. Once the data
     transfer job has been processed and verified, AWS performs a software erasure
     of the Snowball appliance.

** Snowball Edge
   - is a 100TB data transfer device with on-board storage and compute capabilities.
     You can use snowball Edge to move large amounts of data into and out of AWS,
     as a temporary storage tier for large local datasets, or to support local
     workloads in remote or offline locations.
     Snowball Edge connects to your existing applications and infrastructure using
     standard storage interfaces, streamlining the data transfer process and
     minimizing setup and integration. Snowball Edge can cluster together to form
     a local storage tier and process your data on-premises, helping ensure your
     applications continue to run even when they are not able to access the cloud.

** Snowmobile
   - Is an Exabyte-scale data transfer service used to move extremely large amounts
     of data to AWS. You can transfer up to 100PB per Snowmobile, a 45-foot long
     ruggdized shipping container, pulled by a semi-trailer truck. Snowmobile
     makes it easy to move massive volumes of data to the cloud, including video
     libraries, image repositories, or even a complete data center migration.
     Transferring data with Snowmobile is secure, fast and cost effective.

** Snowball Tips
   - Understand what snowball is.
   - Understand what Import Export is.
   - Snowball can:
     * Import to S3.
     * Export to S3.

** S3 Transfer Acceleration
   - Utilises the CloudFront Edge Network to accelerate your uploads to s3.
     Instead of uploading directly to your S3 bucket, you can use a distinct
     URL to upload directly to an edge location which will then transfer that
     file to S3. You will get a distinct URL to upload to.

** S3 Static Website Hosting
   - Format:  http://xairis3website.s3-website-us-east-1.amazonaws.com
